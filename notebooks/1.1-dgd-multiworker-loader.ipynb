{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Workers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Flickr\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "\n",
    "transform = T.Compose([])\n",
    "dataset = Flickr(\"/mnt/nfs-ssd/raw-datasets/pyg-format/Flickr\", transform=transform)\n",
    "data = dataset[0]\n",
    "\n",
    "kwargs = {'batch_size': 64, 'num_workers': 6, 'persistent_workers': True}\n",
    "node_index = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
    "loader = DataLoader(node_index.tolist(), shuffle=True, pin_memory=True, **kwargs)\n",
    "iter_loader = iter(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.utils.data.get_worker_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SubGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "44625"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.subgraph(data.train_mask)\n",
    "train_data.num_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "subg, attr = subgraph(data.train_mask, data.edge_index)\n",
    "subg.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EgoSampler\n",
    "设置最大hop数目，可以限制时间开销随节点budget线性增长\n",
    "时间开销随batch_size线性增长\n",
    "(64) 100: 1.66; 200: 3.0; 400: 4.0\n",
    "(32) 100: 0.7\n",
    "(1) 100: 0.02"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "curPath = os.path.abspath(os.path.dirname('/home/xhh/notebooks/GNN/pytorch-template/notebooks/'))\n",
    "rootPath = os.path.split(curPath)[0]\n",
    "sys.path.append(rootPath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "EgoDataBatch(x=[1538, 500], y=[32], p=[1538], hop=[32], ego_ptr=[32], batch=[1538], ptr=[33], batch_size=32, adj_t=[1538, 1538, nnz=3304])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datamodules.datasets.loader import EgoGraphLoader\n",
    "from src.models.components.assort_sampler import AdaptiveSampler\n",
    "\n",
    "kwargs = {'batch_size': 32,\n",
    "          'num_workers': 0,\n",
    "          'persistent_workers': False,\n",
    "          'pin_memory': False,\n",
    "          'shuffle': True}\n",
    "\n",
    "sampler = AdaptiveSampler(data, 50, max_hop=10)\n",
    "ego_loader = EgoGraphLoader(data.train_mask, sampler, **kwargs)\n",
    "iter_graphs = iter(ego_loader)\n",
    "next(iter_graphs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.72s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "\n",
    "runs = 5\n",
    "for i in range(runs):\n",
    "    batch = next(iter_graphs)\n",
    "\n",
    "print(f'{(time() - t) / runs: .2f}s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensor Batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor\n",
    "import copy\n",
    "from src.datamodules.datasets.loader import to_sparse\n",
    "\n",
    "nd = copy.copy(data)\n",
    "row, col = nd.edge_index.cpu()\n",
    "self_adj_t = SparseTensor(\n",
    "                row=row, col=col,\n",
    "                value=torch.arange(col.size(0)),\n",
    "                sparse_sizes=(data.num_nodes, data.num_nodes)).t()\n",
    "\n",
    "loader = DataLoader(node_index.tolist(), shuffle=True, batch_size=10)\n",
    "iter_loader = iter(loader)\n",
    "batch_nodes = next(iter_loader)\n",
    "batch_size = batch_nodes.size(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(row=tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
      "                           3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 5, 5, 5, 5, 5,\n",
      "                           5, 5, 5, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7, 8, 8, 8, 8, 8, 9, 9, 9, 9,\n",
      "                           9, 9, 9]),\n",
      "             col=tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n",
      "                           28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n",
      "                           46, 47, 48, 49, 50, 51, 52, 22, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62,\n",
      "                           63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80,\n",
      "                           81, 82, 83]),\n",
      "             val=tensor([289655, 378752, 389616, 395895, 413177, 423719, 475812, 573193, 627007,\n",
      "                           790157, 827732, 860831,   8546,  77655,  95388, 510110, 796627,  86920,\n",
      "                           211813, 236211, 369529, 557364, 202023, 267505, 376447, 388192, 436089,\n",
      "                           728903, 799493, 810551, 819191,  48105, 142453, 186539, 215252, 311584,\n",
      "                           486336, 528591, 543133, 566319, 773267, 855547, 877079,   6430, 181362,\n",
      "                           230620, 591094, 599934, 630676, 752320, 811426, 270179, 287372, 308300,\n",
      "                           520137, 556524, 663383,  35324,  73997,  90130, 107216, 113986, 643019,\n",
      "                           175042, 213174, 356122, 458211, 660876, 179921, 196460, 319556, 343852,\n",
      "                           547492, 669161, 683402]),\n",
      "             size=(10, 84), nnz=75, density=8.93%)\n"
     ]
    }
   ],
   "source": [
    "adj_t_1, v = self_adj_t.sample_adj(batch_nodes, -1, replace=False)\n",
    "print(adj_t_1)\n",
    "\n",
    "row, col, layer_e = adj_t_1.coo()\n",
    "\n",
    "e_mask, v_idx, ptr = [], [], []\n",
    "\n",
    "for bn in range(batch_size):\n",
    "    m = row == bn\n",
    "    idx = torch.unique(col[m])\n",
    "    e_mask.append(m)\n",
    "    v_idx.append(idx)\n",
    "    ptr.append(torch.full((len(idx),), bn))\n",
    "\n",
    "true_v = v[torch.cat(v_idx)]\n",
    "batch_idx = torch.cat(ptr)\n",
    "p_v = torch.rand(true_v.size(0))\n",
    "\n",
    "mask = torch.zeros(true_v.size(0), dtype=torch.bool)\n",
    "mask[torch.rand(true_v.size(0)) > 0.5] = 1\n",
    "\n",
    "saved_p = p_v[mask]\n",
    "next_v = true_v[mask]\n",
    "next_idx = batch_idx[mask]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27,\n        28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45,\n        46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63,\n        64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81,\n        82, 83])"
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 针对于每一个batch node的指针\n",
    "torch.cat(true_v.size(0)).unique()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 2, 3, 3, 3, 3, 4, 4, 4, 4, 4, 5, 5, 5, 5, 6,\n        6, 6, 6, 7, 7, 7, 7, 8, 8, 8, 8, 9, 9])"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 拼接成新的u\n",
    "# layer score 基于新的图上面（冗余的边）\n",
    "# ego score 独立\n",
    "next_idx"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "u = v[torch.cat(v_idx)]\n",
    "adj_t_2, u2 = self_adj_t.sample_adj(u, -1, replace=False)\n",
    "row, col, layer_e = adj_t_2.coo()\n",
    "\n",
    "print(adj_t_2, len(u), len(u2), len(u.unique()), len(u2.unique()))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0]) tensor([140])\n"
     ]
    }
   ],
   "source": [
    "# 选中范围\n",
    "node_i = 0\n",
    "print((row == ptr[node_i]).nonzero()[0], (row==ptr[node_i+1]).nonzero()[0])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([   11,    14,    25,  ..., 89197, 89234, 89240]),\n tensor([1349, 2126, 2224,  ..., 6447, 7765, 7908]))"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.unique(u2, return_inverse=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1.],\n        [2., 2., 2., 2.],\n        [3., 3., 3., 3.]])"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ego score\n",
    "# 计算batch_node score\n",
    "# 计算每一层u的score\n",
    "# 根据batch_idx计算cos\n",
    "\n",
    "x = torch.Tensor([[1], [2], [3]])\n",
    "x.expand(3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "PackedSequence(data=tensor([1., 1., 1., 2., 2., 3.]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_sequence, pack_padded_sequence\n",
    "\n",
    "x1 = torch.Tensor([1, 2, 3])\n",
    "x2 = torch.Tensor([1, 2])\n",
    "x3 = torch.Tensor([1])\n",
    "\n",
    "ps = pack_sequence([x1, x2, x3])\n",
    "ps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph Loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[2708, 1433], edge_index=[2, 13264], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datamodules.datasets.data import get_data\n",
    "\n",
    "nd, _, _, _ = get_data('cora')\n",
    "nd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(11857)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "sub = k_hop_subgraph(nd.val_mask, 2, nd.edge_index)\n",
    "sub[3].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[1355, 1433], y=[140], train_mask=[1355], val_mask=[1355], test_mask=[1355], batch_size=140, adj_t=[1355, 1355, nnz=3556], ego_ptr=[140])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import ClusterData\n",
    "from src.datamodules.datasets.loader import NeighborLoader, ClusterLoader, SaintRwLoader, ShadowLoader\n",
    "\n",
    "kwargs = {'batch_size': 512, 'shuffle': True}\n",
    "train_loader = NeighborLoader(nd, input_nodes=nd.train_mask, num_neighbors=[25, 10], **kwargs)\n",
    "# train_loader = ClusterLoader(ClusterData(nd, num_parts=1500, recursive=False, save_dir=dataset.processed_dir,), **kwargs)\n",
    "# train_loader = SaintRwLoader(nd, batch_size=6000, walk_length=2, num_steps=5, sample_coverage=100, save_dir=dataset.processed_dir)\n",
    "# train_loader = ShadowLoader(nd, depth=2, num_neighbors=10, node_idx=data.train_mask, **kwargs)\n",
    "batch = next(train_loader.__iter__())\n",
    "batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-pytorch-gpu-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch-gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}