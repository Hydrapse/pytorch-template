{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "num_feature = 5000\n",
    "num_groups = 17\n",
    "ls = list(range(0, num_feature, int(num_feature / num_groups)))\n",
    "ls[-1] = num_feature"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "Parameter containing:\ntensor([[0.0000e+00],\n        [1.4486e-39],\n        [1.5102e-36],\n        ...,\n        [1.4486e-39],\n        [6.0395e-36],\n        [3.5733e-43]], requires_grad=True)"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.parameter import Parameter\n",
    "from torch import nn\n",
    "\n",
    "w_ego_root = [Parameter(torch.Tensor(num_feature)), Parameter(torch.Tensor(num_feature, 1))]\n",
    "w_ego_root[1]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 294, 296]\n",
      "[0, 294, 588, 882, 1176, 1470, 1764, 2058, 2352, 2646, 2940, 3234, 3528, 3822, 4116, 4410, 4704, 5000]\n"
     ]
    }
   ],
   "source": [
    "group_size = int(num_feature / num_groups)\n",
    "x_ptr = list(range(0, num_feature, group_size))\n",
    "x_ptr[-1] = num_feature\n",
    "num_features = [group_size] * num_groups\n",
    "num_features[-1] += num_feature % num_groups\n",
    "print(num_features, x_ptr, sep='\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/build/aten/src/ATen/RegisterCPU.cpp:21063 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/build/aten/src/ATen/RegisterCUDA.cpp:29726 [kernel]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1258 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradMLC: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/TraceType_3.cpp:11220 [kernel]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m                       Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-50-072c3d1f15d6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0mt2\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mTensor\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m47\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m43\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m40\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m26\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m46\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m18\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m21\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;36m6\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m37\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m43\u001B[0m\u001B[0;34m,\u001B[0m  \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;36m16\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mzeros_like\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mt1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdtype\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbool\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 4\u001B[0;31m \u001B[0mtorch\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mNotImplementedError\u001B[0m: There were no tensor arguments to this function (e.g., you passed an empty list of Tensors), but no fallback function is registered for schema aten::_cat.  This usually means that this function requires a non-empty list of Tensors, or that you (the operator writer) forgot to register a fallback function.  Available functions are [CPU, CUDA, QuantizedCPU, BackendSelect, Python, Named, Conjugate, Negative, ZeroTensor, ADInplaceOrView, AutogradOther, AutogradCPU, AutogradCUDA, AutogradXLA, AutogradLazy, AutogradXPU, AutogradMLC, AutogradHPU, AutogradNestedTensor, AutogradPrivateUse1, AutogradPrivateUse2, AutogradPrivateUse3, Tracer, AutocastCPU, Autocast, Batched, VmapMode, Functionalize].\n\nCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/build/aten/src/ATen/RegisterCPU.cpp:21063 [kernel]\nCUDA: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/build/aten/src/ATen/RegisterCUDA.cpp:29726 [kernel]\nQuantizedCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/build/aten/src/ATen/RegisterQuantizedCPU.cpp:1258 [kernel]\nBackendSelect: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/BackendSelectFallbackKernel.cpp:3 [backend fallback]\nPython: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/PythonFallbackKernel.cpp:47 [backend fallback]\nNamed: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/NamedRegistrations.cpp:7 [backend fallback]\nConjugate: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ConjugateFallback.cpp:18 [backend fallback]\nNegative: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/native/NegateFallback.cpp:18 [backend fallback]\nZeroTensor: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/ZeroTensorFallback.cpp:86 [backend fallback]\nADInplaceOrView: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/core/VariableFallbackKernel.cpp:64 [backend fallback]\nAutogradOther: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradCPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradCUDA: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradXLA: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradLazy: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradXPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradMLC: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradHPU: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradNestedTensor: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse1: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse2: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nAutogradPrivateUse3: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/VariableType_3.cpp:11380 [autograd kernel]\nTracer: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/torch/csrc/autograd/generated/TraceType_3.cpp:11220 [kernel]\nAutocastCPU: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:461 [backend fallback]\nAutocast: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/autocast_mode.cpp:305 [backend fallback]\nBatched: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/BatchingRegistrations.cpp:1059 [backend fallback]\nVmapMode: fallthrough registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/VmapModeRegistrations.cpp:33 [backend fallback]\nFunctionalize: registered at /opt/conda/conda-bld/pytorch_1646755903507/work/aten/src/ATen/FunctionalizeFallbackKernel.cpp:52 [backend fallback]\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.Tensor([49, 48, 47, 46, 45, 47, 48, 41, 44, 43, 44, 48, 47, 31, 43])\n",
    "t2 = torch.Tensor([47, 43, 40,  0,  0, 26, 46, 18, 21,  0,  6, 37, 43,  0, 16])\n",
    "len(t1[torch.zeros_like(t1, dtype=bool)])\n",
    "torch.cat([torch.Tensor([])])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-pytorch-gpu-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch-gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}