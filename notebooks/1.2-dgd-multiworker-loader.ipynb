{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Multi-Workers"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "outputs": [],
   "source": [
    "from torch_geometric.datasets import Flickr\n",
    "from torch.utils.data import DataLoader\n",
    "import torch_geometric.transforms as T\n",
    "import torch\n",
    "\n",
    "transform = T.Compose([T.AddSelfLoops()])\n",
    "dataset = Flickr(\"/mnt/nfs-ssd/raw-datasets/pyg-format/Flickr\", transform=transform)\n",
    "data = dataset[0]\n",
    "\n",
    "kwargs = {'batch_size': 64, 'num_workers': 6, 'persistent_workers': True}\n",
    "node_index = data.train_mask.nonzero(as_tuple=False).view(-1)\n",
    "loader = DataLoader(node_index.tolist(), shuffle=True, pin_memory=True, **kwargs)\n",
    "iter_loader = iter(loader)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "torch.utils.data.get_worker_info()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# SubGraph"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "data": {
      "text/plain": "44625"
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = data.subgraph(data.train_mask)\n",
    "train_data.num_nodes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from torch_geometric.utils import subgraph\n",
    "\n",
    "subg, attr = subgraph(data.train_mask, data.edge_index)\n",
    "subg.size()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# EgoSampler\n",
    "设置最大hop数目，可以限制时间开销随节点budget线性增长\n",
    "时间开销随batch_size线性增长\n",
    "(64) 100: 1.66; 200: 3.0; 400: 4.0\n",
    "(32) 100: 0.7\n",
    "(1) 100: 0.02"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/xhh', 'notebooks')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('/home/xhh/notebooks/GNN/pytorch-template/notebooks/')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "EgoDataBatch(x=[1538, 500], y=[32], p=[1538], hop=[32], ego_ptr=[32], batch=[1538], ptr=[33], batch_size=32, adj_t=[1538, 1538, nnz=3304])"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datamodules.datasets.loader import EgoGraphLoader\n",
    "from src.models.components.assort_sampler import AdaptiveSampler\n",
    "\n",
    "kwargs = {'batch_size': 32,\n",
    "          'num_workers': 0,\n",
    "          'persistent_workers': False,\n",
    "          'pin_memory': False,\n",
    "          'shuffle': True\n",
    "          }\n",
    "\n",
    "sampler = AdaptiveSampler(data, 50, max_hop=10)\n",
    "ego_loader = EgoGraphLoader(data.train_mask, sampler, **kwargs)\n",
    "iter_graphs = iter(ego_loader)\n",
    "next(iter_graphs)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Time Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.72s\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "t = time()\n",
    "\n",
    "runs = 5\n",
    "for i in range(runs):\n",
    "    batch = next(iter_graphs)\n",
    "\n",
    "print(f'{(time() - t) / runs: .2f}s')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tensor Batch"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "outputs": [],
   "source": [
    "from torch_sparse import SparseTensor\n",
    "import copy\n",
    "from src.datamodules.datasets.loader import to_sparse\n",
    "\n",
    "nd = copy.copy(data)\n",
    "row, col = nd.edge_index.cpu()\n",
    "self_adj_t = SparseTensor(\n",
    "                row=row, col=col,\n",
    "                value=torch.arange(col.size(0)),\n",
    "                sparse_sizes=(data.num_nodes, data.num_nodes)).t()\n",
    "\n",
    "loader = DataLoader(node_index.tolist(), shuffle=True, batch_size=10)\n",
    "iter_loader = iter(loader)\n",
    "\n",
    "batch_nodes = next(iter_loader)\n",
    "batch_size = batch_nodes.size(0)\n",
    "batch_ptr = torch.arange(batch_nodes.size(0))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "虽然mask的长度等于每一层的edge数目，但是采样的概率每个点的不同边都相同，本质上还是对点采样。"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(row=tensor([0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "                           2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4,\n",
      "                           4, 4, 5, 5, 5, 5, 5, 5, 5, 5, 5, 6, 6, 6, 6, 6, 6, 6, 7, 7, 7, 7, 7, 7,\n",
      "                           7, 7, 7, 7, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 9, 9, 9, 9]),\n",
      "             col=tensor([ 0, 10, 11, 12, 13, 14, 15,  1, 16, 17, 18, 19, 20,  2, 21, 22, 23, 24,\n",
      "                           25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39,  3, 40, 41,\n",
      "                           42, 43, 44, 45, 46, 47, 48,  4, 49, 50, 51, 52, 53, 54,  5, 55, 56, 57,\n",
      "                           58, 59, 60, 61, 62,  6, 63, 64, 65, 66, 67, 68,  7, 69, 70, 71, 72, 73,\n",
      "                           74, 75, 76, 77,  8, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87,  9, 88, 89,\n",
      "                           90, 91, 92]),\n",
      "             val=tensor([905388, 126264, 143733, 191227, 295451, 468778, 501083, 980311,  39678,\n",
      "                            70685, 155770, 349704, 426132, 911647, 137910, 172012, 222745, 289809,\n",
      "                           335534, 389695, 395119, 485293, 493800, 507293, 517913, 540388, 614958,\n",
      "                           619268, 748891, 763914, 818475, 883820, 896952, 910743, 277744, 315925,\n",
      "                           395894, 400755, 499449, 609719, 692496, 774907, 880377, 939832, 335218,\n",
      "                           451048, 451155, 521582, 572680, 851620, 954553, 186944, 213393, 283848,\n",
      "                           293802, 490914, 779326, 857571, 890678, 961282,   8326,  47125, 138610,\n",
      "                           608852, 620633, 848076, 931870,  52378, 191175, 402107, 500253, 562066,\n",
      "                           585156, 598507, 650652, 730993, 916650,  61636, 149274, 251228, 301671,\n",
      "                           321183, 352351, 442214, 661924, 885315, 896032, 931399, 250202, 408616,\n",
      "                           522909, 616479, 621123]),\n",
      "             size=(10, 93), nnz=93, density=10.00%)\n"
     ]
    }
   ],
   "source": [
    "# hop loop\n",
    "adj_t_1, v = self_adj_t.sample_adj(batch_nodes, -1, replace=False)\n",
    "print(adj_t_1)\n",
    "\n",
    "row, col, layer_e = adj_t_1.coo()\n",
    "\n",
    "v_idx, ptrs, edge_inv = [], [], []\n",
    "row = torch.cat([row, torch.Tensor([batch_size]).to(int)])\n",
    "for bn in range(batch_size):\n",
    "    ptr = (batch_ptr == bn).nonzero(as_tuple=True)[0]\n",
    "    ptr_start, ptr_end = (row == ptr[0]).nonzero()[0], (row == ptr[-1]+1).nonzero()[0]\n",
    "    idx, inv = torch.unique(col[ptr_start:ptr_end], return_inverse=True)\n",
    "    edge_inv.append(ptr_start + inv)\n",
    "    v_idx.append(idx)\n",
    "    ptrs.append(torch.full((len(idx),), bn))\n",
    "edge_inv = torch.cat(edge_inv)\n",
    "v_idx = torch.cat(v_idx)\n",
    "batch_idx = torch.cat(ptrs)\n",
    "\n",
    "true_v = v[v_idx]\n",
    "p_v = torch.rand(true_v.size(0))\n",
    "\n",
    "mask = torch.zeros(true_v.size(0), dtype=torch.bool)\n",
    "mask[torch.rand(true_v.size(0)) > 0.5] = 1\n",
    "\n",
    "saved_p = p_v[mask]\n",
    "saved_v = true_v[mask]\n",
    "batch_ptr = batch_idx[mask]\n",
    "saved_e = layer_e[mask[edge_inv]]\n",
    "batch_e_ptr = batch_idx[edge_inv][mask[edge_inv]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SparseTensor(row=tensor([ 0,  0,  0,  ..., 41, 41, 41]),\n",
      "             col=tensor([   0,    1,    2,  ..., 7606, 7607, 7608]),\n",
      "             val=tensor([905388, 126264, 295451,  ..., 769512, 789102, 882301]),\n",
      "             size=(42, 7609), nnz=7781, density=2.43%)\n"
     ]
    }
   ],
   "source": [
    "adj_t_2, v = self_adj_t.sample_adj(saved_v, -1, replace=False)\n",
    "print(adj_t_2)\n",
    "row, col, layer_e = adj_t_2.coo()\n",
    "\n",
    "v_idx, ptrs, edge_inv = [], [], []\n",
    "row = torch.cat([row, torch.Tensor([len(saved_v)]).to(int)])\n",
    "inc = 0\n",
    "for bn in range(batch_size):\n",
    "    ptr = (batch_ptr == bn).nonzero(as_tuple=True)[0]\n",
    "    ptr_start, ptr_end = (row == ptr[0]).nonzero()[0], (row == ptr[-1]+1).nonzero()[0]\n",
    "    idx, inv = torch.unique(col[ptr_start:ptr_end], return_inverse=True)\n",
    "    v_idx.append(idx)\n",
    "    edge_inv.append(inc + inv)\n",
    "    ptrs.append(torch.full((len(idx),), bn))\n",
    "    inc += len(idx)\n",
    "edge_inv = torch.cat(edge_inv)\n",
    "v_idx = torch.cat(v_idx)\n",
    "batch_idx = torch.cat(ptrs)\n",
    "\n",
    "true_v = v[v_idx]\n",
    "p_v = torch.rand(true_v.size(0))\n",
    "\n",
    "mask = torch.zeros(true_v.size(0), dtype=torch.bool)\n",
    "mask[torch.rand(true_v.size(0)) > 0.5] = 1\n",
    "\n",
    "saved_p2 = p_v[mask]\n",
    "saved_v2 = true_v[mask]\n",
    "batch_ptr2 = batch_idx[mask]\n",
    "saved_e2 = layer_e[mask[edge_inv]]\n",
    "batch_e_ptr2 = batch_idx[edge_inv][mask[edge_inv]]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "outputs": [],
   "source": [
    "n_p = torch.cat([torch.ones(batch_size), saved_p, saved_p2])\n",
    "n_id = torch.cat([batch_nodes, saved_v, saved_v2])\n",
    "e_id = torch.cat([saved_e, saved_e2])\n",
    "n_batch = torch.cat([torch.arange(batch_size).to(int), batch_ptr, batch_ptr2])\n",
    "e_batch = torch.cat([batch_e_ptr, batch_e_ptr2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "outputs": [
    {
     "data": {
      "text/plain": "EgoDataBatch(x=[3890, 500], edge_index=[2, 3936], y=[10], p=[3890], ego_ptr=[10], batch=[3890], ptr=[11], batch_size=10)"
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.data import Batch\n",
    "from src.models.components.assort_sampler import EgoData\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.utils import sort_edge_index\n",
    "edge_index = data.edge_index\n",
    "\n",
    "egos = []\n",
    "for bn in range(batch_size):\n",
    "    bn_mask = n_batch == bn\n",
    "    n_idx, inv_ptr = n_id[bn_mask].unique(return_inverse=True)\n",
    "    p = scatter(n_p[bn_mask], inv_ptr, dim=-1, reduce='sum')\n",
    "\n",
    "    \"\"\"unique的inv是一个很优雅的local-e, 而且idx是排序过的unique节点id，和p的unique对应上\"\"\"\n",
    "    sub_edge_index = edge_index[:, e_id[e_batch == bn]]\n",
    "    local_e = sort_edge_index(sub_edge_index.unique(return_inverse=True)[1])\n",
    "\n",
    "    ego_data = EgoData(data.x[n_idx], local_e, data.y[n_idx[inv_ptr[0]]], p)\n",
    "    ego_data.ego_ptr = inv_ptr[0]\n",
    "    egos.append(ego_data)\n",
    "\n",
    "batch_data = Batch.from_data_list(egos)\n",
    "batch_data.ego_ptr = (batch_data.ego_ptr + batch_data.ptr[:-1])\n",
    "batch_data.batch_size = batch_data.ego_ptr.size(0)\n",
    "batch_data"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "得到完整的edge-id以及对应的batch—ptr, 使用scatter来为每个batch—node构造子图"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 0, 0, 0, 0, 1, 1, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 4, 4, 4, 4, 4, 4, 5,\n",
      "         5, 5, 6, 6, 6, 6, 7, 7, 7, 7, 8, 8, 9, 9, 9, 9]]) tensor([[289655, 413177, 423719, 475812, 790157,  95388, 510110, 211813, 236211,\n",
      "         557364, 202023, 267505, 376447, 388192, 436089, 728903, 799493,  48105,\n",
      "         142453, 215252, 528591, 566319, 877079, 181362, 752320, 811426, 270179,\n",
      "         287372, 308300, 556524,  35324,  90130, 107216, 113986, 213174, 356122,\n",
      "         179921, 196460, 343852, 669161]])\n"
     ]
    }
   ],
   "source": [
    "batch_e_ptr.unsqueeze_(dim=0)\n",
    "saved_e.unsqueeze_(dim=0)\n",
    "print(batch_e_ptr, saved_e)\n",
    "\n",
    "split = torch.full((batch_size, batch_e_ptr.size(-1)), -1, dtype=saved_e.dtype).scatter_(0, batch_e_ptr, saved_e)\n",
    "split"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1., 1., 1., 1.],\n        [2., 2., 2., 2.],\n        [3., 3., 3., 3.]])"
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ego score\n",
    "# 计算batch_node score\n",
    "# 计算每一层u的score\n",
    "# 根据batch_idx计算cos\n",
    "\n",
    "x = torch.Tensor([[1], [2], [3]])\n",
    "x.expand(3, 4)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "PackedSequence(data=tensor([1., 1., 1., 2., 2., 3.]), batch_sizes=tensor([3, 2, 1]), sorted_indices=None, unsorted_indices=None)"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.nn.utils.rnn import pack_sequence\n",
    "\n",
    "x1 = torch.Tensor([1, 2, 3])\n",
    "x2 = torch.Tensor([1, 2])\n",
    "x3 = torch.Tensor([1])\n",
    "\n",
    "ps = pack_sequence([x1, x2, x3])\n",
    "ps"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Graph Loader"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[2708, 1433], edge_index=[2, 13264], y=[2708], train_mask=[2708], val_mask=[2708], test_mask=[2708])"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.datamodules.datasets.data import get_data\n",
    "\n",
    "nd, _, _, _ = get_data('cora')\n",
    "nd"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor(11857)"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import k_hop_subgraph\n",
    "\n",
    "sub = k_hop_subgraph(nd.val_mask, 2, nd.edge_index)\n",
    "sub[3].sum()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "Data(x=[1355, 1433], y=[140], train_mask=[1355], val_mask=[1355], test_mask=[1355], batch_size=140, adj_t=[1355, 1355, nnz=3556], ego_ptr=[140])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.loader import ClusterData\n",
    "from src.datamodules.datasets.loader import NeighborLoader, ClusterLoader, SaintRwLoader, ShadowLoader\n",
    "\n",
    "kwargs = {'batch_size': 512, 'shuffle': True}\n",
    "train_loader = NeighborLoader(nd, input_nodes=nd.train_mask, num_neighbors=[25, 10], **kwargs)\n",
    "# train_loader = ClusterLoader(ClusterData(nd, num_parts=1500, recursive=False, save_dir=dataset.processed_dir,), **kwargs)\n",
    "# train_loader = SaintRwLoader(nd, batch_size=6000, walk_length=2, num_steps=5, sample_coverage=100, save_dir=dataset.processed_dir)\n",
    "# train_loader = ShadowLoader(nd, depth=2, num_neighbors=10, node_idx=data.train_mask, **kwargs)\n",
    "batch = next(train_loader.__iter__())\n",
    "batch"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "conda-env-pytorch-gpu-py",
   "language": "python",
   "display_name": "Python [conda env:pytorch-gpu]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}