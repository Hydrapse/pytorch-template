# @package _global_

# to execute this experiment run:
# python run.py experiment=example

defaults:
  - override /mode: exp.yaml
  - override /trainer: default.yaml
  - override /model: gnn.yaml
  - override /datamodule: adaptive.yaml
  - override /callbacks: default.yaml
  - override /logger:
    - neptune.yaml
#    - mlflow.yaml

# all parameters below will be merged with parameters from default configurations set above
# this allows you to overwrite only specified parameters

# name of the run determines folder name in logs
# can also be accessed by loggers
name: "adaptive-sampler"

seed: 123

trainer:
  min_epochs: 0
  max_epochs: 2
#  gradient_clip_val: 0.5
  gpus: [0]
#  strategy: ddp

datamodule:
  num_workers: 20
  # dataset
  dataset: pubmed
  split: full
  batch_size: 64
  undirected: True
  # training
  lr: 0.001
  weight_decay: 1e-5
  # adapt
  node_budget: 50
  alpha: 0.2
  max_hop: 10
  max_degree: 16
  min_nodes: 64
  num_groups: 1
  group_type: full
  ego_mode: False
  to_single_layer: False

model:
  model: sage
  lr: 0.001
  # adapt
  subg_pool: []
  pool_type: max
  # base
  hidden_channels: 128
  conv_layers: 2
  dropout: 0.3
  dropedge: 0
  residual: null
  jk: null



# 覆盖掉logger配置
#logger:
#  mlflow:
#    run_name: run3  # 指定实验名

#logger:
#  csv:
#    name: csv/${name}
#  wandb:
#    tags: ["mnist", "simple_dense_net"]